import { GoogleGenAI, Type } from "@google/genai";

const getAiClient = () => {
  const apiKey = process.env.API_KEY;
  if (!apiKey) {
    throw new Error("API Key not found in environment variables");
  }
  return new GoogleGenAI({ apiKey });
};

// Helper to convert base64 to standard format if needed, though GenAI handles raw base64 usually
const cleanBase64 = (base64Str: string) => {
  return base64Str.replace(/^data:image\/(png|jpeg|jpg|webp);base64,/, "");
};

const getMimeType = (base64Str: string) => {
  const match = base64Str.match(/^data:(image\/[a-zA-Z+]+);base64,/);
  return match ? match[1] : "image/jpeg";
};

/**
 * Uses gemini-3-pro-preview to analyze the image and generate funny captions.
 */
export const generateMemeCaptions = async (base64Image: string): Promise<string[]> => {
  const ai = getAiClient();
  const modelId = "gemini-3-pro-preview";

  const mimeType = getMimeType(base64Image);
  const data = cleanBase64(base64Image);

  try {
    const response = await ai.models.generateContent({
      model: modelId,
      contents: {
        parts: [
          {
            inlineData: {
              mimeType,
              data,
            },
          },
          {
            text: "Analyze this image and generate 5 funny, viral-worthy, short meme captions that fit the context perfectly. Return the result as a JSON array of strings.",
          },
        ],
      },
      config: {
        responseMimeType: "application/json",
        responseSchema: {
          type: Type.ARRAY,
          items: {
            type: Type.STRING,
          },
        },
      },
    });

    const text = response.text;
    if (!text) return [];
    
    // Parse the JSON array
    const captions = JSON.parse(text);
    return Array.isArray(captions) ? captions : [];
  } catch (error) {
    console.error("Error generating captions:", error);
    throw error;
  }
};

/**
 * Uses gemini-2.5-flash-image (Nano banana) to edit the image based on a prompt.
 */
export const editMemeImage = async (base64Image: string, prompt: string): Promise<string> => {
  const ai = getAiClient();
  const modelId = "gemini-2.5-flash-image"; // "Nano banana" equivalent

  const mimeType = getMimeType(base64Image);
  const data = cleanBase64(base64Image);

  try {
    const response = await ai.models.generateContent({
      model: modelId,
      contents: {
        parts: [
          {
            inlineData: {
              mimeType,
              data,
            },
          },
          {
            text: `Edit this image: ${prompt}. Keep the main subject but apply the requested changes strictly. Return only the image.`,
          },
        ],
      },
      // Note: responseSchema/responseMimeType is not supported well for image output on this model yet in all contexts,
      // but the model returns image parts.
    });

    // Iterate parts to find the image
    const parts = response.candidates?.[0]?.content?.parts;
    if (parts) {
      for (const part of parts) {
        if (part.inlineData && part.inlineData.data) {
          return `data:${part.inlineData.mimeType || 'image/png'};base64,${part.inlineData.data}`;
        }
      }
    }
    
    throw new Error("No image generated by the model.");
  } catch (error) {
    console.error("Error editing image:", error);
    throw error;
  }
};
